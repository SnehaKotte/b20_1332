{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SnehaKotte/b20_1332/blob/main/IEEE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stB4AbjAH-8q",
        "outputId": "f367d73b-d938-461d-f1e7-88e82d50f7a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows, cols: (3547, 11)\n",
            "Columns: ['hour_of_day', 'cash_type', 'money', 'coffee_name', 'Time_of_Day', 'Weekday', 'Month_name', 'Weekdaysort', 'Monthsort', 'Date', 'Time']\n",
            "Number of classes: 8\n",
            "Numeric cols: ['hour_of_day', 'hour_sin', 'hour_cos', 'money', 'Weekdaysort', 'Monthsort']\n",
            "Categorical cols: ['cash_type', 'Time_of_Day', 'Weekday', 'Month_name']\n",
            "\n",
            "======== LogisticRegression ========\n",
            "Test Accuracy: 0.6352  F1-macro: 0.5413  F1-micro: 0.6352\n",
            "Top-level metrics:\n",
            "              precision  recall  f1-score\n",
            "accuracy          0.635   0.635     0.635\n",
            "macro avg         0.587   0.535     0.541\n",
            "weighted avg      0.614   0.635     0.606\n",
            "\n",
            "======== RandomForest ========\n",
            "Test Accuracy: 0.6141  F1-macro: 0.5399  F1-micro: 0.6141\n",
            "Top-level metrics:\n",
            "              precision  recall  f1-score\n",
            "accuracy          0.614   0.614     0.614\n",
            "macro avg         0.588   0.523     0.540\n",
            "weighted avg      0.614   0.614     0.609\n",
            "\n",
            "======== ExtraTrees ========\n",
            "Test Accuracy: 0.5944  F1-macro: 0.5617  F1-micro: 0.5944\n",
            "Top-level metrics:\n",
            "              precision  recall  f1-score\n",
            "accuracy          0.594   0.594     0.594\n",
            "macro avg         0.574   0.554     0.562\n",
            "weighted avg      0.592   0.594     0.591\n",
            "\n",
            "======== GradientBoosting ========\n",
            "Test Accuracy: 0.6366  F1-macro: 0.5858  F1-micro: 0.6366\n",
            "Top-level metrics:\n",
            "              precision  recall  f1-score\n",
            "accuracy          0.637   0.637     0.637\n",
            "macro avg         0.605   0.578     0.586\n",
            "weighted avg      0.628   0.637     0.627\n",
            "\n",
            "======== AdaBoost ========\n",
            "Test Accuracy: 0.3873  F1-macro: 0.2058  F1-micro: 0.3873\n",
            "Top-level metrics:\n",
            "              precision  recall  f1-score\n",
            "accuracy          0.387   0.387     0.387\n",
            "macro avg         0.209   0.266     0.206\n",
            "weighted avg      0.319   0.387     0.310\n",
            "\n",
            "======== SVM-RBF ========\n",
            "Test Accuracy: 0.6592  F1-macro: 0.5313  F1-micro: 0.6592\n",
            "Top-level metrics:\n",
            "              precision  recall  f1-score\n",
            "accuracy          0.659   0.659     0.659\n",
            "macro avg         0.700   0.536     0.531\n",
            "weighted avg      0.690   0.659     0.609\n",
            "\n",
            "======== KNN ========\n",
            "Test Accuracy: 0.4239  F1-macro: 0.3433  F1-micro: 0.4239\n",
            "Top-level metrics:\n",
            "              precision  recall  f1-score\n",
            "accuracy          0.424   0.424     0.424\n",
            "macro avg         0.473   0.342     0.343\n",
            "weighted avg      0.435   0.424     0.405\n",
            "\n",
            "======== GaussianNB ========\n",
            "Test Accuracy: 0.4085  F1-macro: 0.4033  F1-micro: 0.4085\n",
            "Top-level metrics:\n",
            "              precision  recall  f1-score\n",
            "accuracy          0.408   0.408     0.408\n",
            "macro avg         0.413   0.439     0.403\n",
            "weighted avg      0.463   0.408     0.414\n",
            "\n",
            "Saved summary metrics to ./reports/summary_metrics.csv\n",
            "✅ Done. Models saved to ./models\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "import joblib\n",
        "\n",
        "# --------------------------\n",
        "# Config\n",
        "# --------------------------\n",
        "DATA_PATH = \"/content/data_set.xlsx\"   # default path in Colab\n",
        "SHEET_NAME = \"Coffe_sales\"\n",
        "TARGET_COL = \"coffee_name\"\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "OUT_DIR = \"./reports\"\n",
        "MODEL_DIR = \"./models\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# --------------------------\n",
        "# Load dataset (with fallback upload)\n",
        "# --------------------------\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"⚠️ File not found. Please upload data_set.xlsx\")\n",
        "        uploaded = files.upload()\n",
        "        DATA_PATH = list(uploaded.keys())[0]   # take the uploaded file name\n",
        "    except Exception as e:\n",
        "        raise FileNotFoundError(\"Please upload 'data_set.xlsx' or update DATA_PATH with the correct location.\") from e\n",
        "\n",
        "df = pd.read_excel(DATA_PATH, sheet_name=SHEET_NAME)\n",
        "\n",
        "# --------------------------\n",
        "# Basic preprocessing\n",
        "# --------------------------\n",
        "print(\"Rows, cols:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "if 'Date' in df.columns:\n",
        "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "if 'Time' in df.columns:\n",
        "    df['Time_str'] = df['Time'].astype(str)\n",
        "\n",
        "if 'hour_of_day' not in df.columns:\n",
        "    if 'Time' in df.columns:\n",
        "        try:\n",
        "            df['hour_of_day'] = pd.to_datetime(df['Time'].astype(str), errors='coerce').dt.hour\n",
        "        except Exception:\n",
        "            df['hour_of_day'] = pd.to_datetime(df['Time_str'].astype(str), errors='coerce').dt.hour\n",
        "    elif 'dt' in df.columns:\n",
        "        df['hour_of_day'] = pd.to_datetime(df['dt'], errors='coerce').dt.hour\n",
        "    else:\n",
        "        df['hour_of_day'] = np.nan\n",
        "\n",
        "df['hour_sin'] = np.sin(2 * np.pi * df['hour_of_day'] / 24)\n",
        "df['hour_cos'] = np.cos(2 * np.pi * df['hour_of_day'] / 24)\n",
        "\n",
        "if 'Weekday' in df.columns:\n",
        "    df['Weekday'] = df['Weekday'].astype(str)\n",
        "\n",
        "if 'money' in df.columns:\n",
        "    df['money'] = pd.to_numeric(df['money'], errors='coerce')\n",
        "\n",
        "candidate_features = [\n",
        "    'hour_of_day','hour_sin','hour_cos',\n",
        "    'cash_type','Time_of_Day','Weekday','Month_name',\n",
        "    'money','Weekdaysort','Monthsort'\n",
        "]\n",
        "features = [c for c in candidate_features if c in df.columns]\n",
        "\n",
        "df = df[~df[TARGET_COL].isna()].copy()\n",
        "y = df[TARGET_COL].astype(str).copy()\n",
        "\n",
        "lbl = LabelEncoder()\n",
        "y_enc = lbl.fit_transform(y)\n",
        "print(\"Number of classes:\", len(lbl.classes_))\n",
        "\n",
        "X = df[features].copy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_enc, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_enc\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# Preprocessing pipeline\n",
        "# --------------------------\n",
        "num_cols = [c for c in X_train.columns if X_train[c].dtype.kind in 'biufc']\n",
        "cat_cols = [c for c in X_train.columns if c not in num_cols]\n",
        "\n",
        "print(\"Numeric cols:\", num_cols)\n",
        "print(\"Categorical cols:\", cat_cols)\n",
        "\n",
        "num_pipe = Pipeline([\n",
        "    ('impute', SimpleImputer(strategy='median')),\n",
        "    ('scale', StandardScaler())\n",
        "])\n",
        "\n",
        "cat_pipe = Pipeline([\n",
        "    ('impute', SimpleImputer(strategy='constant', fill_value='MISSING')),\n",
        "    ('ohe', OneHotEncoder(handle_unknown='ignore')) # Removed sparse=False\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', num_pipe, num_cols),\n",
        "    ('cat', cat_pipe, cat_cols)\n",
        "], remainder='drop')\n",
        "\n",
        "preprocessor.fit(X_train)\n",
        "\n",
        "X_train_t = preprocessor.transform(X_train)\n",
        "X_test_t  = preprocessor.transform(X_test)\n",
        "\n",
        "joblib.dump(preprocessor, os.path.join(MODEL_DIR, \"preprocessor.joblib\"))\n",
        "\n",
        "# --------------------------\n",
        "# Classifiers\n",
        "# --------------------------\n",
        "classifiers = {\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=400, multi_class='multinomial', solver='lbfgs', random_state=RANDOM_STATE),\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1),\n",
        "    \"ExtraTrees\": ExtraTreesClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1),\n",
        "    \"GradientBoosting\": GradientBoostingClassifier(n_estimators=200, random_state=RANDOM_STATE),\n",
        "    \"AdaBoost\": AdaBoostClassifier(n_estimators=200, random_state=RANDOM_STATE),\n",
        "    \"SVM-RBF\": SVC(kernel='rbf', probability=True, random_state=RANDOM_STATE),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=7, n_jobs=-1),\n",
        "    \"GaussianNB\": GaussianNB()\n",
        "}\n",
        "\n",
        "summary_rows = []\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "for name, clf in classifiers.items():\n",
        "    print(\"\\n========\", name, \"========\")\n",
        "    clf.fit(X_train_t, y_train)\n",
        "    joblib.dump(clf, os.path.join(MODEL_DIR, f\"{name}.joblib\"))\n",
        "\n",
        "    y_pred = clf.predict(X_test_t)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
        "    precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"Test Accuracy: {acc:.4f}  F1-macro: {f1_macro:.4f}  F1-micro: {f1_micro:.4f}\")\n",
        "\n",
        "    try:\n",
        "        cv_scores = cross_val_score(clf, preprocessor.transform(X), lbl.transform(y), cv=cv, scoring='f1_macro', n_jobs=-1)\n",
        "        cv_mean = cv_scores.mean()\n",
        "    except Exception:\n",
        "        cv_mean = np.nan\n",
        "\n",
        "    summary_rows.append({\n",
        "        \"model\": name,\n",
        "        \"accuracy\": acc,\n",
        "        \"f1_macro\": f1_macro,\n",
        "        \"f1_micro\": f1_micro,\n",
        "        \"precision_macro\": precision_macro,\n",
        "        \"recall_macro\": recall_macro,\n",
        "        \"cv_f1_macro\": cv_mean\n",
        "    })\n",
        "\n",
        "    crep = classification_report(y_test, y_pred, target_names=lbl.classes_, output_dict=True, zero_division=0)\n",
        "    crep_df = pd.DataFrame(crep).transpose()\n",
        "    crep_df.to_csv(os.path.join(OUT_DIR, f\"classification_report_{name}.csv\"), index=True)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    cm_df = pd.DataFrame(cm, index=lbl.classes_, columns=lbl.classes_)\n",
        "    cm_df.to_csv(os.path.join(OUT_DIR, f\"confusion_matrix_{name}.csv\"))\n",
        "\n",
        "    print(\"Top-level metrics:\")\n",
        "    print(crep_df.loc[['accuracy','macro avg','weighted avg'], ['precision','recall','f1-score']].round(3))\n",
        "\n",
        "summary_df = pd.DataFrame(summary_rows).sort_values('f1_macro', ascending=False)\n",
        "summary_df.to_csv(os.path.join(OUT_DIR, \"summary_metrics.csv\"), index=False)\n",
        "print(\"\\nSaved summary metrics to\", os.path.join(OUT_DIR, \"summary_metrics.csv\"))\n",
        "\n",
        "le_map = pd.DataFrame({\n",
        "    \"class_label\": lbl.classes_,\n",
        "    \"class_index\": range(len(lbl.classes_))\n",
        "})\n",
        "le_map.to_csv(os.path.join(OUT_DIR, \"label_mapping.csv\"), index=False)\n",
        "\n",
        "print(\"✅ Done. Models saved to\", MODEL_DIR)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMu5Wt4vQZ9q4YvYJpIqyJZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}